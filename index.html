<h1>Qiang Zhou (周强)</h1>
<p>Homepage: <a href="https://mightyzau.github.io">https://mightyzau.github.io</a></p>

<img src="photo.png" 
     width="200" 
     height="200" />


<h2 id="education-and-work-experience">Education and Work Experience</h2>
<hr/>

<ul>
<li><p>2019 - now, Conducting visual algorithm research in Alibaba DAMO Academy.</p>
</li>
<li><p>2014 - 2019, PhD student at Zhejiang University.</p>
</li>
</ul>
<ul>
<li>2010 - 2014, Undergraduate student at Nanjing University of Science and Technology.</li>
</ul>


<h2>Publications</h2>

<hr/>

<p><strong>Qiang Zhou</strong>, Chaohui Yu, Jingliang Li, Yuang Liu, Jing Wang, Zhibin Wang. <a href="https://arxiv.org/abs/2308.02191" title="XX">ES-MVSNet: Efficient Framework for End-to-end Self-supervised Multi-View Stereo</a> (arxiv 2023)</p>

<p>Yuang Liu, <strong>Qiang Zhou</strong>, Jing Wang, Fan Wang, Jun Wang, Wei Zhang. <a href="https://arxiv.org/abs/2308.01944" title="XX">Dynamic Token-Pass Transformers for Semantic Segmentation</a> (arxiv 2023)</p>

<p><strong>Qiang Zhou</strong>, Chaohui Yu, Shaofeng Zhang, Sitong Wu, Zhibing Wang, Fan Wang. <a href="https://arxiv.org/abs/2308.02299" title="XX">RegionBLIP: A Unified Multi-modal Pre-training Framework for Holistic and Regional Comprehension</a> (arxiv 2023)</p>

<p>Jingliang Li, <strong>Qiang Zhou</strong>, Chaohui Yu, Zhengda Lu, Jun Xiao, Zhibin Wang, Fan Wang. <a href="https://arxiv.org/abs/2308.03772v1" title="XX">Improved Neural Radiance Fields Using Pseudo-depth and Fusion</a> (arxiv 2023)</p>

<p>Chaohui Yu, <strong>Qiang Zhou</strong>, Jingliang Li, Zhe Zhang, Zhibin Wang, Fan Wang. <a href="https://arxiv.org/abs/2307.13908v1" title="XX">Points-to-3D: Bridging the Gap between Sparse Points and Shape-Controllable Text-to-3D Generation</a> (ACM MM 2023)</p>

<p>Shaofeng Zhang, <strong>Qiang Zhou</strong>, Zhibin Wang, Fan Wang, Junchi Yan. Patch-level Contrastive Learning via Positional Query for Visual Pre-training. (ICML 2023)</p>

<p>Chaohui Yu, <strong>Qiang Zhou</strong>, Jingliang Li, Jianlong Yuan, Zhibin Wang, Fan Wang. <a href="https://arxiv.org/pdf/2302.14250.pdf" title="XX">Foundation Model Drives Weakly Incremental Learning for Semantic Segmentation.</a> (CVPR 2023)</p>

<p> <strong>Qiang Zhou</strong>, Yuang Liu, Chaohui Yu, Jinliang Li, Zhibin Wang, Fan Wang. <a href="https://arxiv.org/pdf/2302.13495.pdf">LMSeg: Language-guided Multi-dataset Segmentation.</a> (ICLR 2023)</p>

<p><strong>Qiang Zhou</strong>, Chaohui Yu, Zhibin Wang, Fan Wang. <a href="https://arxiv.org/abs/2303.00542">D2Q-DETR: Decoupling and Dynamic Queries for Oriented Object Detection with Transformers.</a> (ICASSP 2023)</p>

<p>Yongtao Ge, <strong>Qiang Zhou</strong>, Xinlong Wang, Chunhua Shen, Zhibin Wang, Hao Li. <a href="https://arxiv.org/abs/2206.00274">Point-Teaching: Weakly Semi-Supervised Object Detection with Point Annotations</a>. (AAAI 2023)</p>

<p><strong>Qiang Zhou</strong>, Chaohui Yu, Chunhua Shen, Zhibin Wang, Hao Li. <a href="https://arxiv.org/abs/2101.11782">Object Detection Made Simpler by Eliminating Heuristic NMS</a> (IEEE Transactions on Multimedia, 2023)</p>

<p><strong>Qiang Zhou</strong>, Chaohui Yu. <a href="https://www.mdpi.com/2072-4292/14/11/2605">Point RCNN: An Angle-Free Framework for Rotated Object Detection</a>. (Remote Sensing, 2022)</p>

<p><strong>Qiang Zhou</strong>, Chaohui Yu, Hao Luo, Zhibin Wang, Hao Li. <a href="https://dl.acm.org/doi/abs/10.1145/3503161.3548173">MimCo: Masked Image Modeling Pre-training with Contrastive Teacher</a>. (ACM MM 2022)</p>

<p><strong>Qiang Zhou</strong>, Chaohui Yu, Zhibin Wang, Qi Qian, Hao Li. <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Zhou_Instant-Teaching_An_End-to-End_Semi-Supervised_Object_Detection_Framework_CVPR_2021_paper.pdf">Instant-Teaching: An End-to-End Semi-Supervised Object Detection Framework</a>. (CVPR 2021)</p>

<p>Qiang Zhou, Xin Li. <a href="https://link.springer.com/article/10.1007/s10846-019-01096-w">Visual positioning of distant wall-climbing robots using convolutional neural networks.</a> (Journal of Intelligent &amp; Robotic Systems, 2019)</p>

<p>Qiang Zhou, Xin Li. <a href="https://www.mdpi.com/2076-3417/9/23/5187">STN-homography: Direct estimation of homography parameters for image pairs.</a>(Applied Sciences, 2019)</p>

<p>Qiang Zhou, Xin Li. <a href="https://www.mdpi.com/2076-3417/9/14/2908">Deep homography estimation and its application to wall maps of wall-climbing robots.</a> (Applied Sciences, 2019)</p>

<p>Qiang Zhou, Xin Li. <a href="https://www.sciencedirect.com/science/article/abs/pii/S0921889016307710">Experimental investigation on climbing robot using rotation-flow adsorption unit.</a>  (Robotics and Autonomous Systems, 2018)</p>

<p>Qiang Zhou, Xin Li. <a href="https://ieeexplore.ieee.org/abstract/document/7759847/">Design of wall-climbing robot using electrically activated rotational-flow adsorption unit</a> (IROS, 2016)</p>

<p>Qiang Zhou, Xin Li. <a href="https://www.emerald.com/insight/content/doi/10.1108/IR-01-2016-0020/full/html?utm_campaign=Emerald_Engineering_PPV_Dec22_RoN">Experimental comparison of drag-wiper and roller-wiper glass-cleaning robots.</a> (Industrial Robot: An International Journal, 2016)</p>


<h2 id="competition">Competition</h2>
<hr/>

<ul>
<li><p>1st place, LUAI Challenge 2021 on Learning To Understand Aerial Images at ICCV 2021. <a href="https://openaccess.thecvf.com/content/ICCV2021W/LUAI/papers/Xia_LUAI_Challenge_2021_on_Learning_To_Understand_Aerial_Images_ICCVW_2021_paper.pdf">Technical reports</a>.</p>
</li>
<li><p>2nd place，<a href="https://www.lvisdataset.org/challenge_2020">LVIS Challenge 2020 at EECV 2020</a>. <a href="https://www.lvisdataset.org/assets/challenge_reports/2020/TXunAI.pdf">Technical reports</a>.</p>
</li>
</ul>


<h2>联系方式</h2>

<hr/>

<p><strong>Email</strong>: mightyzau@gmail.com；zhouqiang@zju.edu.cn</p>
